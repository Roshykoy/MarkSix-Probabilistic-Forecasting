{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Notebook 3: CVAE Inference and Evaluation\n\nThis notebook demonstrates the advanced inference and evaluation capabilities of the new CVAE-based system. It shows how to generate number combinations using the trained CVAE model with graph neural networks, temporal context, and meta-learning ensemble optimization. The evaluation measures the model's performance using sophisticated probabilistic metrics.",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "import torch\nimport pandas as pd\nimport numpy as np\nimport joblib\nfrom tqdm.notebook import tqdm\nimport random\nimport os\nimport sys\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Add the source directory to the Python path\nsys.path.append(os.path.abspath(os.path.join('..')))\n\n# Import all necessary components from our new CVAE-based architecture\nfrom src.config import CONFIG\nfrom src.cvae_model import CVAEModel\nfrom src.graph_encoder import GraphEncoder\nfrom src.temporal_context import TemporalContextModel\nfrom src.meta_learner import MetaLearner\nfrom src.feature_engineering import FeatureEngineer\nfrom src.inference_pipeline import CVAEInferencePipeline\nfrom src.evaluation_pipeline import CVAEEvaluationPipeline\nfrom src.visualization import create_inference_plots, create_evaluation_plots\n\nprint(\"Setup complete. New CVAE inference modules loaded.\")\nprint(f\"Device available: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 2. Load CVAE Model and Components\n\nThe new architecture requires loading multiple components: the CVAE model, graph encoder, temporal context, meta-learner, and feature engineer.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Check if CVAE model artifacts exist\nconservative_model_path = os.path.join('..', 'models', 'conservative_cvae_model.pth')\nconservative_fe_path = os.path.join('..', 'models', 'conservative_feature_engineer.pkl')\n\n# Fallback to regular model paths\nmodel_path = os.path.join('..', 'models', 'scoring_model.pth')\nfe_path = os.path.join('..', 'models', 'feature_engineer.pkl')\n\n# Check which model artifacts are available\nif os.path.exists(conservative_model_path) and os.path.exists(conservative_fe_path):\n    model_path, fe_path = conservative_model_path, conservative_fe_path\n    print(\"Loading conservative CVAE model artifacts...\")\nelif os.path.exists(model_path) and os.path.exists(fe_path):\n    print(\"Loading standard model artifacts...\")\nelse:\n    print(\"Model artifacts not found! Please run the training pipeline first.\")\n    print(\"Expected files:\")\n    print(f\"  - {conservative_model_path}\")\n    print(f\"  - {conservative_fe_path}\")\n    raise FileNotFoundError(\"Model artifacts missing\")\n\n# Setup device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Load feature engineer\nfeature_engineer = joblib.load(fe_path)\nprint(f\"Feature engineer loaded. Feature dimension: {feature_engineer.get_feature_dim()}\")\n\n# Load historical data for model components\ncol_names = [\n    'Draw', 'Date', 'Winning_Num_1', 'Winning_Num_2', 'Winning_Num_3',\n    'Winning_Num_4', 'Winning_Num_5', 'Winning_Num_6', 'Extra_Num',\n    'From_Last', 'Low', 'High', 'Odd', 'Even', '1-10', '11-20', '21-30',\n    '31-40', '41-50', 'Div_1_Winners', 'Div_1_Prize', 'Div_2_Winners',\n    'Div_2_Prize', 'Div_3_Winners', 'Div_3_Prize', 'Div_4_Winners',\n    'Div_4_Prize', 'Div_5_Winners', 'Div_5_Prize', 'Div_6_Winners',\n    'Div_6_Prize', 'Div_7_Winners', 'Div_7_Prize', 'Turnover'\n]\n\ndata_path = os.path.join('..', CONFIG[\"data_path\"])\ndf = pd.read_csv(data_path, header=None, skiprows=33, names=col_names)\ndf['Date'] = pd.to_datetime(df['Date'])\ndf = df.sort_values(by='Date').reset_index(drop=True)\n\nprint(f\"Historical data loaded: {len(df)} draws from {df['Date'].min()} to {df['Date'].max()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 3. Initialize CVAE Architecture and Load Trained Weights\n\nRecreate the complete CVAE architecture and load the trained model weights.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Initialize graph encoder for number relationships\ngraph_encoder = GraphEncoder(\n    num_nodes=CONFIG['num_lotto_numbers'],\n    input_dim=CONFIG['graph_input_dim'],\n    hidden_dim=CONFIG['graph_hidden_dim'],\n    output_dim=CONFIG['graph_output_dim']\n).to(device)\n\n# Initialize temporal context model\ntemporal_model = TemporalContextModel(\n    input_dim=CONFIG['temporal_input_dim'],\n    hidden_dim=CONFIG['temporal_hidden_dim'],\n    output_dim=CONFIG['temporal_output_dim']\n).to(device)\n\n# Initialize meta-learner for ensemble optimization\nmeta_learner = MetaLearner(\n    input_dim=CONFIG['meta_input_dim'],\n    hidden_dim=CONFIG['meta_hidden_dim'],\n    num_scorers=CONFIG['num_ensemble_scorers']\n).to(device)\n\n# Initialize main CVAE model\ncvae_model = CVAEModel(\n    feature_dim=feature_engineer.get_feature_dim(),\n    latent_dim=CONFIG['cvae_latent_dim'],\n    hidden_dim=CONFIG['cvae_hidden_dim'],\n    graph_encoder=graph_encoder,\n    temporal_encoder=temporal_model,\n    meta_learner=meta_learner\n).to(device)\n\n# Load trained weights\ntry:\n    cvae_model.load_state_dict(torch.load(model_path, map_location=device))\n    cvae_model.eval()\n    print(f\"CVAE model loaded successfully from {model_path}\")\n    print(f\"Model has {sum(p.numel() for p in cvae_model.parameters())} parameters\")\nexcept Exception as e:\n    print(f\"Error loading CVAE model: {e}\")\n    print(\"Attempting to load as legacy model...\")\n    # Fallback code for legacy models could go here\n    raise\n\nprint(\"CVAE model initialized and loaded for inference!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 4. Advanced CVAE Inference: Generate Number Combinations\n\nUse the sophisticated CVAE inference pipeline to generate high-quality number combinations with confidence scores.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "### 6. Advanced CVAE Model Evaluation\n\nEvaluate the CVAE model's performance using sophisticated metrics including reconstruction quality, latent space coherence, and predictive performance.",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Initialize the advanced evaluation pipeline\nevaluation_pipeline = CVAEEvaluationPipeline(\n    cvae_model=cvae_model,\n    feature_engineer=feature_engineer,\n    config=CONFIG,\n    device=device\n)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"COMPREHENSIVE CVAE MODEL EVALUATION\")\nprint(\"=\"*60)\n\n# Split data for evaluation\ntrain_size = int(len(df) * 0.85)\nval_df = df.iloc[train_size:].reset_index(drop=True)\n\nprint(f\"Evaluating on {len(val_df)} validation draws...\")\n\n# Run comprehensive evaluation\nevaluation_results = evaluation_pipeline.evaluate_comprehensive(val_df)\n\nprint(\"\\n1. RECONSTRUCTION QUALITY\")\nprint(\"-\" * 30)\nprint(f\"Reconstruction Loss: {evaluation_results['reconstruction_loss']:.4f}\")\nprint(f\"Reconstruction Accuracy: {evaluation_results['reconstruction_accuracy']:.2f}%\")\nprint(f\"Feature Correlation: {evaluation_results['feature_correlation']:.3f}\")\n\nprint(\"\\n2. LATENT SPACE ANALYSIS\")\nprint(\"-\" * 30) \nprint(f\"KL Divergence: {evaluation_results['kl_divergence']:.4f}\")\nprint(f\"Latent Space Utilization: {evaluation_results['latent_utilization']:.2f}%\")\nprint(f\"Latent Consistency: {evaluation_results['latent_consistency']:.3f}\")\n\nprint(\"\\n3. GENERATIVE QUALITY\")\nprint(\"-\" * 30)\nprint(f\"Sample Diversity: {evaluation_results['sample_diversity']:.3f}\")\nprint(f\"Historical Similarity: {evaluation_results['historical_similarity']:.3f}\")\nprint(f\"Pattern Capture Score: {evaluation_results['pattern_capture']:.3f}\")\n\nprint(\"\\n4. PREDICTIVE PERFORMANCE\")\nprint(\"-\" * 30)\nprint(f\"Win Rate vs Random: {evaluation_results['win_rate']:.2f}%\")\nprint(f\"Ranking Correlation: {evaluation_results['ranking_correlation']:.3f}\")\nprint(f\"Confidence Calibration: {evaluation_results['confidence_calibration']:.3f}\")\n\nprint(\"\\n5. ENSEMBLE PERFORMANCE\")\nprint(\"-\" * 30)\nprint(f\"Meta-Learner Accuracy: {evaluation_results['meta_accuracy']:.2f}%\")\nprint(f\"Ensemble Improvement: {evaluation_results['ensemble_improvement']:.2f}%\")\nprint(f\"Weight Stability: {evaluation_results['weight_stability']:.3f}\")\n\n# Create evaluation visualization\nfig, axes = plt.subplots(2, 3, figsize=(18, 12))\n\n# Reconstruction quality over time\naxes[0, 0].plot(evaluation_results['reconstruction_timeline'])\naxes[0, 0].set_title('Reconstruction Quality Timeline')\naxes[0, 0].set_xlabel('Draw Number')\naxes[0, 0].set_ylabel('Reconstruction Loss')\n\n# Latent space visualization (2D projection)\nlatent_samples = evaluation_results['latent_samples']\naxes[0, 1].scatter(latent_samples[:, 0], latent_samples[:, 1], alpha=0.6)\naxes[0, 1].set_title('Latent Space Visualization (2D)')\naxes[0, 1].set_xlabel('Latent Dimension 1')\naxes[0, 1].set_ylabel('Latent Dimension 2')\n\n# Win rate progression\naxes[0, 2].plot(evaluation_results['win_rate_progression'])\naxes[0, 2].set_title('Win Rate Progression')\naxes[0, 2].set_xlabel('Evaluation Step')\naxes[0, 2].set_ylabel('Win Rate %')\n\n# Confidence calibration curve\naxes[1, 0].plot(evaluation_results['confidence_bins'], evaluation_results['accuracy_bins'])\naxes[1, 0].plot([0, 1], [0, 1], 'r--', alpha=0.5)\naxes[1, 0].set_title('Confidence Calibration')\naxes[1, 0].set_xlabel('Confidence')\naxes[1, 0].set_ylabel('Accuracy')\n\n# Ensemble weight evolution\nweights_evolution = evaluation_results['weights_evolution']\nfor i, weight_series in enumerate(weights_evolution.T):\n    axes[1, 1].plot(weight_series, label=f'Scorer {i+1}')\naxes[1, 1].set_title('Ensemble Weight Evolution')\naxes[1, 1].set_xlabel('Evaluation Step')\naxes[1, 1].set_ylabel('Weight')\naxes[1, 1].legend()\n\n# Performance comparison\nmethods = ['CVAE', 'Graph Only', 'Temporal Only', 'Meta Only', 'Full Ensemble']\nperformances = evaluation_results['component_comparison']\naxes[1, 2].bar(methods, performances)\naxes[1, 2].set_title('Component Performance Comparison')\naxes[1, 2].set_ylabel('Win Rate %')\naxes[1, 2].tick_params(axis='x', rotation=45)\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\n\" + \"=\"*60)\nprint(\"EVALUATION SUMMARY\")\nprint(\"=\"*60)\nprint(f\"Overall Model Performance: {evaluation_results['overall_score']:.2f}/100\")\nprint(f\"Recommendation: {evaluation_results['recommendation']}\")\nprint(\"=\"*60)",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Initialize the advanced inference pipeline\ninference_pipeline = CVAEInferencePipeline(\n    cvae_model=cvae_model,\n    feature_engineer=feature_engineer,\n    config=CONFIG,\n    device=device\n)\n\n# Fit the pipeline with historical data\nprint(\"Fitting inference pipeline with historical data...\")\ninference_pipeline.fit(df)\n\n# Generate multiple number sets with different approaches\nprint(\"\\n\" + \"=\"*60)\nprint(\"GENERATING NUMBER COMBINATIONS\")\nprint(\"=\"*60)\n\n# Method 1: Pure CVAE sampling\nprint(\"\\n1. CVAE Latent Space Sampling\")\nprint(\"-\" * 40)\ncvae_sets = inference_pipeline.generate_sets_cvae_sampling(\n    num_sets=5,\n    num_samples=CONFIG['inference_samples']\n)\n\nfor i, (combo, score, confidence) in enumerate(cvae_sets, 1):\n    print(f\"Set {i}: {combo} (Score: {score:.4f}, Confidence: {confidence:.3f})\")\n\n# Method 2: Meta-learned ensemble with CVAE guidance\nprint(\"\\n2. Meta-Learned Ensemble Generation\")\nprint(\"-\" * 40)\nensemble_sets = inference_pipeline.generate_sets_meta_ensemble(\n    num_sets=5,\n    use_cvae_guidance=True\n)\n\nfor i, (combo, score, confidence) in enumerate(ensemble_sets, 1):\n    print(f\"Set {i}: {combo} (Score: {score:.4f}, Confidence: {confidence:.3f})\")\n\n# Method 3: Hybrid approach with local search\nprint(\"\\n3. Hybrid CVAE + Local Search\")\nprint(\"-\" * 40)\nhybrid_sets = inference_pipeline.generate_sets_hybrid_search(\n    num_sets=5,\n    search_iterations=CONFIG['search_iterations']\n)\n\nfor i, (combo, score, confidence) in enumerate(hybrid_sets, 1):\n    print(f\"Set {i}: {combo} (Score: {score:.4f}, Confidence: {confidence:.3f})\")\n\n# Store results for analysis\nall_generated_sets = {\n    'CVAE Sampling': cvae_sets,\n    'Meta Ensemble': ensemble_sets,\n    'Hybrid Search': hybrid_sets\n}"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}